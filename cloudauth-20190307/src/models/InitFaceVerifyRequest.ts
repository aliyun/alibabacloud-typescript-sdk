// This file is auto-generated, don't edit it
import * as $dara from '@darabonba/typescript';


export class InitFaceVerifyRequest extends $dara.Model {
  /**
   * @remarks
   * Whether the SDK enables strict face quality detection:
   * 
   * - **Y**: Enable
   * 
   * - **N** (default): Disable
   * 
   * 
   * > 
   * > - If this parameter is enabled, the SDK needs to integrate the [strict face quality detection module](https://help.aliyun.com/zh/id-verification/financial-grade-id-verification/description-of-sdk-package-clipping?spm=a2c4g.11186623.0.0.1a9d35c6ySFUPW). Enabling strict quality detection may decrease the success rate of user face recognition.
   * > - Only supported in Android SDK version 2.3.24 and above.
   * 
   * @example
   * N
   */
  appQualityCheck?: string;
  /**
   * @remarks
   * User authorization ID, with a maximum length of 64 characters.
   * 
   * @example
   * 92d46b9e9e2d703f2897f350d5bd4149
   */
  authId?: string;
  /**
   * @remarks
   * Date of birth on the document.
   * 
   * This field is required when the document type **CertType** is **PASSPORT** and **Mode** is **3**.
   * 
   * @example
   * 1993-10-10
   */
  birthday?: string;
  /**
   * @remarks
   * Security token, generated by you, used for preventing duplication and tampering.
   * 
   * If this value is set, the **CallbackToken** field will be displayed in the callback address.
   * 
   * @example
   * NMjvQanQgplBSaEI0sL86WnQplB
   */
  callbackToken?: string;
  /**
   * @remarks
   * Callback notification address for the authentication result, with the default callback request method being GET. The callback address must start with `https`. After completing the authentication, the platform will call back this address and automatically add the `certifyId` and `passed` fields, where the value of the `passed` field is the subcode, for example: `https://www.aliyun.com?callbackToken=1000004826&certifyId=shaxxxx&passed=200`.
   * 
   * <notice>
   * 
   * - Callbacks are triggered only when the authentication is completed (including both successful and unsuccessful authentications). If the authentication is abandoned, interrupted abnormally, or not performed, no notification will be sent. It is recommended that you retrieve detailed authentication information through a query interface if needed after receiving the callback notification.
   * - The accessibility of the provided address will be verified before the API call. If the address cannot be accessed over the public network, a 401 error will be returned.
   * - The callback interface must return an HTTP status code of 200; otherwise, it will trigger a retry, with two callbacks within 3 seconds.
   * 
   * </notice>
   * 
   * @example
   * https://www.aliyun.com
   */
  callbackUrl?: string;
  /**
   * @remarks
   * Whether to enable the camera selection feature:
   * 
   * - **Y**: Enable
   * 
   * - **N** (default): Disable
   * 
   * > This feature only takes effect in PC integration mode. When enabled, it allows users to select the camera for authentication.
   * 
   * @example
   * N
   */
  cameraSelection?: string;
  /**
   * @remarks
   * Real name.
   * 
   * @example
   * 张三
   */
  certName?: string;
  /**
   * @remarks
   * Document number.
   * 
   * @example
   * 330103xxxxxxxxxxxx
   */
  certNo?: string;
  /**
   * @remarks
   * Document type.
   * Currently, only IDENTITY_CARD (ID card) is supported.
   * 
   * @example
   * IDENTITY_CARD
   */
  certType?: string;
  /**
   * @remarks
   * >Warning: To be deprecated
   * 
   * Previously passed CertifyId for real-person authentication, where the photo taken during authentication is used as the comparison photo.
   * 
   * > Among the four image input methods (FaceContrastPicture, FaceContrastPictureUrl, CertifyId, OSS), choose one to input.
   * 
   * @example
   * 0bfa7c493f850e5178b9f8613634c9xx
   */
  certifyId?: string;
  /**
   * @remarks
   * Types of **CertifyUrl** returned, including:
   * 
   * - **L**: Original long link
   * 
   * - **S** (default): Short link
   * 
   * @example
   * L
   */
  certifyUrlStyle?: string;
  /**
   * @remarks
   * Web SDK device type, with values **WEB** or **H5**.
   * 
   * > Only Web SDK device types are supported.
   * 
   * @example
   * WEB
   */
  certifyUrlType?: string;
  /**
   * @remarks
   * Whether to allow cropping of the face image, with the default being not allowed.
   * 
   * - T: Indicates allowing cropping.
   * 
   * - F: Indicates not allowing cropping.
   * 
   * > If the image you are requesting is not from a standard liveness detection SDK, it is recommended to allow face image cropping. When this feature is enabled, the requested image will first undergo face cropping and alignment, and then the service request will be initiated.
   * 
   * @example
   * T
   */
  crop?: string;
  /**
   * @remarks
   * Encryption algorithm to be used, currently supporting only the SM2 national encryption algorithm.
   * 
   * After enabling encrypted transmission, you need to pass in the encrypted CertName and CertNo. For how to encrypt, please refer to [Parameter Encryption Instructions](https://help.aliyun.com/zh/id-verification/financial-grade-id-verification/description-of-parameter-encryption?spm=a2c4g.11186623.0.0.1a9d566eWdqwy8#task-2229332).
   * 
   * @example
   * SM2
   */
  encryptType?: string;
  /**
   * @remarks
   * Base64 encoded photo.
   * 
   * > Choose one of the following methods to upload the image: FaceContrastPicture, FaceContrastPictureUrl, CertifyId, or OSS.
   * 
   * @example
   * /9j/4AAQSkZJRgABAQAASxxxxxxx
   */
  faceContrastPicture?: string;
  /**
   * @remarks
   * OSS photo address, currently only supports authorized OSS photo addresses.
   * 
   * > Among the four image input methods (FaceContrastPicture, FaceContrastPictureUrl, CertifyId, OSS), choose one to input.
   * 
   * @example
   * https://cn-shanghai-aliyun-cloudauth-xxxxxx.oss-cn-shanghai.aliyuncs.com/verify/xxxxx/xxxxx.jpeg
   */
  faceContrastPictureUrl?: string;
  /**
   * @remarks
   * Device assistant label type, with the value: **DeviceRisk**.
   * 
   * >
   * > - Choosing to output the device assistant will incur additional costs. For details, see [Paid Value-Added Services](https://help.aliyun.com/zh/id-verification/financial-grade-id-verification/face-guard?spm=a2c4g.11186623.0.0.443e5522rbHsR4).
   * > - If you do not need to output the device assistant label, you can either not pass the parameter or pass an empty value.
   * 
   * @example
   * DeviceRisk
   */
  faceGuardOutput?: string;
  /**
   * @remarks
   * User\\"s IP address.
   * 
   * @example
   * 114.xxx.xxx.xxx
   */
  ip?: string;
  /**
   * @remarks
   * Metainfo environment parameter, which needs to be obtained through the client SDK.
   * 
   * @example
   * {"zimVer":"3.0.0","appVersion": "1","bioMetaInfo": "4.1.0:11501568,0","appName": "com.aliyun.antcloudauth","deviceType": "ios","osVersion": "iOS 10.3.2","apdidToken": "","deviceModel": "iPhone9,1"}
   */
  metaInfo?: string;
  /**
   * @remarks
   * User\\"s phone number.
   * 
   * @example
   * 130xxxxxxxx
   */
  mobile?: string;
  /**
   * @remarks
   * Method to obtain passport NFC verification elements:
   * 
   * - **1**: User input, where the end-user manually inputs the document information using the UI interface provided by the Alibaba Cloud SDK.
   * 
   * - **3**: External parameter input, where the document information is passed through external parameters.
   * 
   * > When decoding the encrypted information from the passport chip using NFC, three elements of the passport need to be obtained, including name, date of birth, and document expiration date.
   * 
   * @example
   * 1
   */
  mode?: string;
  /**
   * @remarks
   * Liveness detection type, with values:
   * > Only the following liveness detection types are supported; custom actions or combinations are not supported at this time.
   * 
   * Note
   * Only the following liveness detection types are supported; custom actions or combinations are not supported at this time.
   * 
   * - **LIVENESS** (default): Blinking
   * 
   * - **PHOTINUS_LIVENESS**: Blinking + Colorful Light
   * 
   * - **MULTI_ACTION**: Blinking + Head Shaking (the order of blinking and head shaking is random)
   * 
   * - **MOVE_ACTION** (recommended): Moving Closer and Farther + Blinking
   * 
   * - **MOVE_PHOTINUS**: Moving Closer and Farther + Colorful Light
   * 
   * > 
   * >- The **default liveness detection type** is supported in the following versions:
   * >   - Android SDK 1.2.6 and above
   * >   - iOS SDK 1.2.4 and above
   * >   - Harmony SDK 1.0.0 and above
   * >- Other types are supported in the latest SDK versions for Android/iOS/Harmony. It is recommended to integrate the latest version.
   * 
   * @example
   * MOVE_ACTION
   */
  model?: string;
  /**
   * @remarks
   * Whether to intercept when multiple faces are detected, with the following values:
   * 
   * - **Y**: Intercept, and the client prompts the user to re-scan their face.
   * 
   * - **N** (default): Do not intercept, and send the largest face in the scanned image to the server for security checks.
   * 
   * @example
   * Y
   */
  needMultiFaceCheck?: string;
  /**
   * @remarks
   * Authorized OSS bucket name.
   * 
   * > Among the four image input methods (FaceContrastPicture, FaceContrastPictureUrl, CertifyId, OSS), choose one to input.
   * 
   * @example
   * cn-shanghai-aliyun-cloudauth-xxxxx
   */
  ossBucketName?: string;
  /**
   * @remarks
   * Authorized OSS object name.
   * 
   * > Among the four image input methods (FaceContrastPicture, FaceContrastPictureUrl, CertifyId, OSS), choose one to input.
   * 
   * @example
   * verify/xxxxx/xxxxxx.jpeg
   */
  ossObjectName?: string;
  /**
   * @remarks
   * Unique identifier for the merchant\\"s request.
   * 
   * The value is a 32-character alphanumeric combination. The first few characters are a custom abbreviation defined by the merchant, followed by a period, and the latter part can be a random or incremental sequence.
   * 
   * @example
   * e0c34a77f5ac40a5aa5e6ed20c353888
   */
  outerOrderNo?: string;
  /**
   * @remarks
   * Degradation configuration for mobile H5 authentication when WebRTC or Webassembly is incompatible.
   * 
   * - **keep**: Does not support degradation, returns directly.
   * 
   * - **url** (default): Supports degradation, returns an authentication URL. Users can use this URL to open or switch browsers for authentication.
   * 
   * - **video**: Supports degradation, uses the system camera to record a 3~5 second blinking video for authentication.
   * 
   * 
   * > 
   * > When the degradation mode is Video, the following functions will be disabled, and the product security will decrease. It is recommended to configure it only for secure scenarios.
   * > - Liveness detection type settings will not take effect.
   * > - The VideoEvidence function is not supported.
   * 
   * @example
   * url
   */
  procedurePriority?: string;
  /**
   * @remarks
   * Fixed value. The parameter value differs based on the product solution:
   * - APP Authentication Scheme: Fixed value is ID_PRO
   * - Live Face Verification Scheme: Fixed value is PV_FV
   * - Liveness Detection Scheme: Fixed value is LR_FR
   * 
   * @example
   * ID_PRO
   */
  productCode?: string;
  /**
   * @remarks
   * Whether to enable rare character mode:
   * 
   * - **Y**: Enable. A message input box will pop up before the user authenticates, requiring the input of the rare character name and ID number. The user must agree to the terms before starting the authentication process.
   * 
   * - **N**: Not enabled (default)
   * 
   * @example
   * Y
   */
  rarelyCharacters?: string;
  /**
   * @remarks
   * Whether to read the document photo:
   * 
   * - **Y**: Read
   * 
   * - **N**: Do not read
   * 
   * > If the document face photo is needed in subsequent authentication steps, it is recommended to set this parameter to Y.
   * 
   * @example
   * Y
   */
  readImg?: string;
  /**
   * @remarks
   * Target URL for the merchant\\"s business page to redirect to.
   * 
   * @example
   * www.aliyun.com
   */
  returnUrl?: string;
  /**
   * @remarks
   * Authentication Scene ID.
   * 
   * @example
   * 1000000006
   */
  sceneId?: number;
  /**
   * @remarks
   * Aging-friendly configuration parameters that take effect for each authentication request. You can choose different parameters based on your app\\"s business attributes, customer distribution, operational characteristics, etc., for each authentication request. The options include the following, with the default being 0.
   * 
   * - **0**: Not enabled, indicating that the current authentication request does not enable aging-friendly mode.
   * 
   * - **1**: Enabled, indicating that the current authentication request enables aging-friendly mode.
   * 
   * - **2**: User choice.
   * 
   * 
   * Supports end-users in choosing the authentication mode. The product guide page provides two authentication entry points: \\"Enable Authentication\\" and \\"Elderly Authentication Mode\\". When the user selects \\"Elderly Authentication Mode\\", the system enters aging-friendly mode.
   * > 
   * > - Aging-friendly parameters are only effective when the liveness detection type **Model** is set to **LIVENESS** or **MULTI_ACTION**.
   * 
   * @example
   * 0
   */
  suitableType?: string;
  /**
   * @remarks
   * UI configuration file URL.
   * 
   * You can view the complete configuration in the [Web SDK UI Customization Description](https://help.aliyun.com/zh/id-verification/financial-grade-id-verification/web-sdk-ui-custom-configuration-description?spm=a2c4g.11186623.0.0.4c683f5c8K3I9p).
   * 
   * @example
   * www.aliyundoc.com
   */
  uiCustomUrl?: string;
  /**
   * @remarks
   * Custom user ID for the customer\\"s business, please ensure it is unique.
   * 
   * @example
   * 123456789
   */
  userId?: string;
  /**
   * @remarks
   * Document expiration date.
   * 
   * This field is required when the document type **CertType** is **PASSPORT** and **Mode** is **3**.
   * 
   * @example
   * 2039-06-10
   */
  validityDate?: string;
  /**
   * @remarks
   * Whether to enable video evidence:
   * 
   * - **true**: Enable
   * 
   * - **false** (default): Disable
   * 
   * > Due to the large size of video files, when the network is unstable, the system will discard the video file to prioritize the transmission of necessary images for authentication. It is recommended that your business set a weak dependency on the video.
   * 
   * @example
   * false
   */
  videoEvidence?: string;
  /**
   * @remarks
   * Customized content. Required when personalized settings are enabled. The format is a JSON String of a String List.
   * 
   * - For the follow-reading scenario: It should not exceed 60 Chinese characters (excluding punctuation), and the List contains only one element.
   * 
   * - For the Q&A scenario: Up to 3 questions can be set, with each question not exceeding 30 Chinese characters, and each question being an element in the List.
   * 
   * @example
   * ["本人王先生同意***协议。"]
   */
  voluntaryCustomizedContent?: string;
  static names(): { [key: string]: string } {
    return {
      appQualityCheck: 'AppQualityCheck',
      authId: 'AuthId',
      birthday: 'Birthday',
      callbackToken: 'CallbackToken',
      callbackUrl: 'CallbackUrl',
      cameraSelection: 'CameraSelection',
      certName: 'CertName',
      certNo: 'CertNo',
      certType: 'CertType',
      certifyId: 'CertifyId',
      certifyUrlStyle: 'CertifyUrlStyle',
      certifyUrlType: 'CertifyUrlType',
      crop: 'Crop',
      encryptType: 'EncryptType',
      faceContrastPicture: 'FaceContrastPicture',
      faceContrastPictureUrl: 'FaceContrastPictureUrl',
      faceGuardOutput: 'FaceGuardOutput',
      ip: 'Ip',
      metaInfo: 'MetaInfo',
      mobile: 'Mobile',
      mode: 'Mode',
      model: 'Model',
      needMultiFaceCheck: 'NeedMultiFaceCheck',
      ossBucketName: 'OssBucketName',
      ossObjectName: 'OssObjectName',
      outerOrderNo: 'OuterOrderNo',
      procedurePriority: 'ProcedurePriority',
      productCode: 'ProductCode',
      rarelyCharacters: 'RarelyCharacters',
      readImg: 'ReadImg',
      returnUrl: 'ReturnUrl',
      sceneId: 'SceneId',
      suitableType: 'SuitableType',
      uiCustomUrl: 'UiCustomUrl',
      userId: 'UserId',
      validityDate: 'ValidityDate',
      videoEvidence: 'VideoEvidence',
      voluntaryCustomizedContent: 'VoluntaryCustomizedContent',
    };
  }

  static types(): { [key: string]: any } {
    return {
      appQualityCheck: 'string',
      authId: 'string',
      birthday: 'string',
      callbackToken: 'string',
      callbackUrl: 'string',
      cameraSelection: 'string',
      certName: 'string',
      certNo: 'string',
      certType: 'string',
      certifyId: 'string',
      certifyUrlStyle: 'string',
      certifyUrlType: 'string',
      crop: 'string',
      encryptType: 'string',
      faceContrastPicture: 'string',
      faceContrastPictureUrl: 'string',
      faceGuardOutput: 'string',
      ip: 'string',
      metaInfo: 'string',
      mobile: 'string',
      mode: 'string',
      model: 'string',
      needMultiFaceCheck: 'string',
      ossBucketName: 'string',
      ossObjectName: 'string',
      outerOrderNo: 'string',
      procedurePriority: 'string',
      productCode: 'string',
      rarelyCharacters: 'string',
      readImg: 'string',
      returnUrl: 'string',
      sceneId: 'number',
      suitableType: 'string',
      uiCustomUrl: 'string',
      userId: 'string',
      validityDate: 'string',
      videoEvidence: 'string',
      voluntaryCustomizedContent: 'string',
    };
  }

  validate() {
    super.validate();
  }

  constructor(map?: { [key: string]: any }) {
    super(map);
  }
}

